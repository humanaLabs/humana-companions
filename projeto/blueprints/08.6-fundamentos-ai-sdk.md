# ğŸ¤– Fundamentos do AI SDK - Guia de ImplementaÃ§Ã£o

## ğŸ“‹ VisÃ£o Geral

Este documento extrai os conceitos fundamentais do AI SDK baseado na documentaÃ§Ã£o oficial em `.cursor/docs/ai-sdk-docs`, focando na implementaÃ§Ã£o prÃ¡tica dentro da nossa aplicaÃ§Ã£o.

> **ğŸ“ Fonte:** Baseado em `.cursor/docs/ai-sdk-docs/02-foundations/` e `.cursor/docs/ai-sdk-docs/02-guides/`

## ğŸ¯ Conceitos Fundamentais

### **ğŸ§  1. Large Language Models (LLMs)**

Um **LLM** Ã© um modelo focado em **texto** que:
- Recebe uma sequÃªncia de palavras como entrada
- Prediz a sequÃªncia mais provÃ¡vel como continuaÃ§Ã£o
- Atribui probabilidades a possÃ­veis prÃ³ximas sequÃªncias
- Continua gerando atÃ© atingir um critÃ©rio de parada

#### **âš ï¸ LimitaÃ§Ãµes Importantes:**
- **Hallucination** - pode inventar informaÃ§Ãµes nÃ£o presentes no treinamento
- **Knowledge Cutoff** - limitado aos dados de treinamento
- **Context Window** - limitaÃ§Ã£o de tokens por requisiÃ§Ã£o

### **ğŸ”— 2. Embedding Models**

Modelos que convertem dados complexos em **vetores densos**:
- **NÃ£o geram** novo conteÃºdo
- **Representam** relaÃ§Ãµes semÃ¢nticas e sintÃ¡ticas
- **Usados para** busca semÃ¢ntica, RAG, clustering

### **ğŸ”„ 3. Streaming**

Resposta em tempo real ao invÃ©s de esperar resposta completa:
```typescript
// Exemplo de streaming na nossa aplicaÃ§Ã£o
const result = await streamText({
  model: openai('gpt-4-turbo'),
  prompt: 'Explique conceitos de IA',
  onChunk: (chunk) => {
    // Atualiza UI em tempo real
    updateChatUI(chunk.text);
  },
});
```

### **ğŸ› ï¸ 4. Tools (Function Calling)**

Permite que LLMs executem funÃ§Ãµes especÃ­ficas:
```typescript
// Exemplo das nossas tools
const tools = {
  createDocument: {
    description: 'Cria um novo documento/artifact',
    parameters: z.object({
      title: z.string(),
      content: z.string(),
      type: z.enum(['text', 'code', 'image', 'sheet']),
    }),
    execute: async ({ title, content, type }) => {
      return await createDocument({ title, content, type });
    },
  },
  updateDocument: {
    description: 'Atualiza documento existente',
    parameters: z.object({
      id: z.string(),
      content: z.string(),
    }),
    execute: async ({ id, content }) => {
      return await updateDocument(id, content);
    },
  },
};
```

## ğŸ—ï¸ ImplementaÃ§Ã£o na Nossa AplicaÃ§Ã£o

### **ğŸ“ Estrutura do AI SDK na AplicaÃ§Ã£o:**

```
ğŸ“ lib/ai/
â”œâ”€â”€ models.ts              # ConfiguraÃ§Ã£o de modelos
â”œâ”€â”€ providers.ts           # Providers (OpenAI, Anthropic)
â”œâ”€â”€ prompts.ts             # Templates de prompts
â”œâ”€â”€ tools/                 # Function calling
â”‚   â”œâ”€â”€ create-document.ts
â”‚   â”œâ”€â”€ update-document.ts
â”‚   â”œâ”€â”€ get-weather.ts
â”‚   â””â”€â”€ request-suggestions.ts
â””â”€â”€ dify-agents.ts         # IntegraÃ§Ã£o Dify
```

### **ğŸ”§ 1. ConfiguraÃ§Ã£o de Providers**

```typescript
// lib/ai/providers.ts
import { openai } from '@ai-sdk/openai';
import { anthropic } from '@ai-sdk/anthropic';

export const providers = {
  openai: {
    'gpt-4-turbo': openai('gpt-4-turbo'),
    'gpt-4o': openai('gpt-4o'),
    'gpt-4o-mini': openai('gpt-4o-mini'),
  },
  anthropic: {
    'claude-3-5-sonnet': anthropic('claude-3-5-sonnet-20241022'),
    'claude-3-5-haiku': anthropic('claude-3-5-haiku-20241022'),
  },
};
```

### **ğŸ”§ 2. ConfiguraÃ§Ã£o de Modelos**

```typescript
// lib/ai/models.ts
export interface ModelConfig {
  id: string;
  provider: 'openai' | 'anthropic';
  name: string;
  description: string;
  maxTokens: number;
  supportsTools: boolean;
  supportsVision: boolean;
}

export const models: ModelConfig[] = [
  {
    id: 'gpt-4-turbo',
    provider: 'openai',
    name: 'GPT-4 Turbo',
    description: 'Modelo mais avanÃ§ado para tarefas complexas',
    maxTokens: 128000,
    supportsTools: true,
    supportsVision: true,
  },
  // ... outros modelos
];
```

### **ğŸ”§ 3. ImplementaÃ§Ã£o de Streaming**

```typescript
// app/(chat)/api/chat/route.ts
import { streamText } from 'ai';
import { providers } from '@/lib/ai/providers';

export async function POST(request: Request) {
  const { messages, model } = await request.json();
  
  const result = await streamText({
    model: providers.openai[model],
    messages,
    tools: {
      createDocument,
      updateDocument,
      getWeather,
      requestSuggestions,
    },
    onFinish: async ({ text, usage }) => {
      // Salva no banco de dados
      await saveChatMessage({
        content: text,
        tokens: usage.totalTokens,
      });
    },
  });

  return result.toDataStreamResponse();
}
```

### **ğŸ”§ 4. Tools Implementation**

```typescript
// lib/ai/tools/create-document.ts
import { z } from 'zod';
import { tool } from 'ai';

export const createDocument = tool({
  description: 'Cria um novo documento ou artifact',
  parameters: z.object({
    title: z.string().describe('TÃ­tulo do documento'),
    content: z.string().describe('ConteÃºdo do documento'),
    type: z.enum(['text', 'code', 'image', 'sheet']).describe('Tipo do documento'),
  }),
  execute: async ({ title, content, type }) => {
    const document = await db.insert(documents).values({
      title,
      content,
      kind: type,
      userId: getCurrentUserId(),
    }).returning();

    return {
      success: true,
      documentId: document[0].id,
      message: `Documento "${title}" criado com sucesso`,
    };
  },
});
```

## ğŸ¯ PadrÃµes de ImplementaÃ§Ã£o

### **ğŸ“ 1. Prompt Engineering**

```typescript
// lib/ai/prompts.ts
export const systemPrompts = {
  assistant: `VocÃª Ã© um assistente IA especializado em criar e editar documentos.

Diretrizes:
- SEMPRE use as tools disponÃ­veis quando apropriado
- Para cÃ³digo, especifique a linguagem corretamente
- Para documentos longos, divida em seÃ§Ãµes
- Mantenha formataÃ§Ã£o consistente

Tools disponÃ­veis:
- createDocument: Para criar novos artifacts  
- updateDocument: Para editar artifacts existentes
- getWeather: Para informaÃ§Ãµes meteorolÃ³gicas
- requestSuggestions: Para sugestÃµes de melhoria`,

  codeReview: `VocÃª Ã© um especialista em revisÃ£o de cÃ³digo.

Analise o cÃ³digo fornecido e:
1. Identifique problemas de seguranÃ§a
2. Sugira melhorias de performance
3. Verifique boas prÃ¡ticas
4. ForneÃ§a exemplos de correÃ§Ã£o

Use a tool updateDocument para aplicar correÃ§Ãµes.`,
};
```

### **ğŸ“ 2. Error Handling**

```typescript
// lib/ai/error-handling.ts
export async function handleAIError(error: unknown) {
  if (error instanceof Error) {
    switch (error.name) {
      case 'AI_APICallError':
        return {
          type: 'api_error',
          message: 'Erro na API do provedor de IA',
          retry: true,
        };
      case 'AI_InvalidPromptError':
        return {
          type: 'prompt_error', 
          message: 'Prompt invÃ¡lido ou muito longo',
          retry: false,
        };
      case 'AI_RateLimitError':
        return {
          type: 'rate_limit',
          message: 'Limite de requisiÃ§Ãµes atingido',
          retry: true,
          retryAfter: 60,
        };
      default:
        return {
          type: 'unknown_error',
          message: 'Erro desconhecido na IA',
          retry: false,
        };
    }
  }
}
```

### **ğŸ“ 3. Usage Tracking**

```typescript
// lib/ai/usage-tracking.ts
export async function trackUsage(params: {
  userId: string;
  model: string;
  promptTokens: number;
  completionTokens: number;
  cost?: number;
}) {
  await db.insert(aiUsage).values({
    userId: params.userId,
    model: params.model,
    promptTokens: params.promptTokens,
    completionTokens: params.completionTokens,
    totalTokens: params.promptTokens + params.completionTokens,
    cost: params.cost,
    timestamp: new Date(),
  });
}
```

## ğŸ”„ RAG (Retrieval Augmented Generation)

### **ğŸ¯ Conceito:**
RAG = **RecuperaÃ§Ã£o** + **GeraÃ§Ã£o Aumentada**
- Busca informaÃ§Ãµes relevantes no knowledge base
- Fornece contexto especÃ­fico para o LLM
- Reduz hallucinations e melhora precisÃ£o

### **ğŸ—ï¸ ImplementaÃ§Ã£o RAG:**

```typescript
// lib/ai/rag.ts
export async function performRAG(query: string) {
  // 1. Gerar embedding da query
  const queryEmbedding = await embed({
    model: openai.embedding('text-embedding-3-small'),
    value: query,
  });

  // 2. Buscar documentos similares
  const similarDocuments = await db
    .select()
    .from(embeddings)
    .where(
      sql`${embeddings.embedding} <-> ${queryEmbedding.embedding} < 0.5`
    )
    .orderBy(
      sql`${embeddings.embedding} <-> ${queryEmbedding.embedding}`
    )
    .limit(5);

  // 3. Construir contexto
  const context = similarDocuments
    .map(doc => doc.content)
    .join('\n\n');

  // 4. Gerar resposta com contexto
  const result = await generateText({
    model: openai('gpt-4-turbo'),
    prompt: `Contexto: ${context}\n\nPergunta: ${query}`,
  });

  return result.text;
}
```

## ğŸ¯ Melhores PrÃ¡ticas

### **âœ… Do's:**
1. **Use streaming** para melhor UX
2. **Implemente tools** para funcionalidades especÃ­ficas  
3. **Track usage** para monitoramento
4. **Handle errors** graciosamente
5. **Validate inputs** antes de enviar para IA
6. **Cache responses** quando apropriado

### **âŒ Don'ts:**
1. **NÃ£o confie cegamente** nas respostas da IA
2. **NÃ£o ignore rate limits** dos providers
3. **NÃ£o exponha API keys** no frontend
4. **NÃ£o processe dados sensÃ­veis** sem criptografia
5. **NÃ£o faÃ§a prompts muito longos** sem necessidade

## ğŸ”— IntegraÃ§Ã£o com Dify

Nossa aplicaÃ§Ã£o tambÃ©m integra com **Dify** para agentes especializados:

```typescript
// lib/ai/dify-agents.ts
export async function callDifyAgent(agentId: string, message: string) {
  const response = await fetch(`${DIFY_API_BASE}/chat-messages`, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${DIFY_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      inputs: {},
      query: message,
      response_mode: 'streaming',
      conversation_id: '',
      user: getCurrentUserId(),
    }),
  });

  return response.body;
}
```

---

## ğŸ¯ Resumo dos Fundamentos

1. **LLMs** - Modelos de texto com limitaÃ§Ãµes conhecidas
2. **Embeddings** - RepresentaÃ§Ã£o vetorial para busca semÃ¢ntica  
3. **Streaming** - Resposta em tempo real
4. **Tools** - Function calling para aÃ§Ãµes especÃ­ficas
5. **RAG** - Conhecimento externo para reduzir hallucinations
6. **Error Handling** - Tratamento robusto de erros
7. **Usage Tracking** - Monitoramento de uso e custos

**ğŸ’¡ O AI SDK abstrai a complexidade de diferentes providers, permitindo foco na lÃ³gica de negÃ³cio!** ğŸš€âœ¨ 